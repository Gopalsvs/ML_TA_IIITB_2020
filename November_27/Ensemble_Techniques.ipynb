{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble Techniques.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mTqlIvcK1IB"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_rnP891e-Uo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EcOkE7Se-Ur"
      },
      "source": [
        "Dataset link: https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ClVOPbKsO4"
      },
      "source": [
        "#Load Data and Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2eRpG9se-Ur"
      },
      "source": [
        "#reading the dataset\n",
        "df=pd.read_csv(\"train.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBTzmNKbe-Us"
      },
      "source": [
        "cols = df.columns\n",
        "\n",
        "for i in cols:\n",
        "    if df[i].isnull().sum() != 0:\n",
        "        print(\"Column name is:\", i)\n",
        "        print(df[i].isnull().sum())\n",
        "\n",
        "#filling missing values\n",
        "print(df['Gender'].value_counts())\n",
        "df['Gender'].fillna('Male', inplace=True)\n",
        "\n",
        "print(df['Married'].value_counts())\n",
        "df['Married'].fillna('Yes', inplace=True)\n",
        "\n",
        "print(df['Dependents'].value_counts())\n",
        "df['Dependents'].fillna('0', inplace=True)\n",
        "\n",
        "print(df['Self_Employed'].value_counts())\n",
        "df['Self_Employed'].fillna('No', inplace=True)\n",
        "\n",
        "print(df.LoanAmount.describe())\n",
        "df['LoanAmount'].fillna(df.LoanAmount.mean(), inplace = True)\n",
        "\n",
        "print(df['Loan_Amount_Term'].value_counts())\n",
        "df['Loan_Amount_Term'].fillna(512, inplace=True)\n",
        "\n",
        "print(df['Credit_History'].value_counts())\n",
        "df['Credit_History'].fillna(1.0, inplace=True)\n",
        "\n",
        "# Get categorical columns\n",
        "cat_cols = []\n",
        "for i in cols:\n",
        "    if df[i].dtypes == 'object' and i!= 'Loan_ID':\n",
        "        print(i)\n",
        "        cat_cols.append(i)\n",
        "\n",
        "# Do label encoding for categorical columns\n",
        "le = LabelEncoder()\n",
        "for i in cat_cols:\n",
        "    df[i] = le.fit_transform(df[i])\n",
        "\n",
        "#split dataset into train and test\n",
        "train, test = train_test_split(df, test_size=0.3, random_state=0)\n",
        "\n",
        "x_train=train.drop(['Loan_Status', 'Loan_ID'], axis=1)\n",
        "y_train=train['Loan_Status']\n",
        "\n",
        "x_test=test.drop(['Loan_Status', 'Loan_ID'], axis=1)\n",
        "y_test=test['Loan_Status']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVL8J_HOe-Uv"
      },
      "source": [
        "#MaxVoting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cim9sktHe-Uv"
      },
      "source": [
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
        "model3 = GaussianNB()\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('NB', model3)])\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BDVHu24e-Uw"
      },
      "source": [
        "# Weighted Averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUYSMEqle-Uw"
      },
      "source": [
        "model1 = tree.DecisionTreeClassifier()\n",
        "model2 = GaussianNB()\n",
        "model3= LogisticRegression()\n",
        "\n",
        "model1.fit(x_train,y_train)\n",
        "model2.fit(x_train,y_train)\n",
        "model3.fit(x_train,y_train)\n",
        "\n",
        "pred1 = model1.predict_proba(x_test)\n",
        "pred2 = model2.predict_proba(x_test)\n",
        "pred3 = model3.predict_proba(x_test)\n",
        "\n",
        "weighted_prediction = (0.2*pred1)+(0.4*pred2)+(0.4*pred3)\n",
        "labelprediction = np.argmax(weighted_prediction, axis = 1)\n",
        "\n",
        "accuracy_score(labelprediction, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gDuXg7ZetGV"
      },
      "source": [
        "model = VotingClassifier(estimators=[('dt', model1), ('gnb', model2), ('lr', model3)],voting='soft',weights=[0.2,0.4,0.4])\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjPV8Fyv8l3O"
      },
      "source": [
        "#Power Averaging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh7AhVyb8oUJ"
      },
      "source": [
        "model1 = tree.DecisionTreeClassifier()\n",
        "model2 = GaussianNB()\n",
        "model3= LogisticRegression()\n",
        "\n",
        "model1.fit(x_train,y_train)\n",
        "model2.fit(x_train,y_train)\n",
        "model3.fit(x_train,y_train)\n",
        "\n",
        "pred1 = model1.predict_proba(x_test)\n",
        "pred2 = model2.predict_proba(x_test)\n",
        "pred3 = model3.predict_proba(x_test)\n",
        "\n",
        "weighted_prediction = ((pred1**2)+(pred2**2)+(pred3**2))/3\n",
        "labelprediction = np.argmax(weighted_prediction, axis = 1)\n",
        "\n",
        "accuracy_score(labelprediction, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94gipq-kikiQ"
      },
      "source": [
        "#Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsKmRuoO8xHB"
      },
      "source": [
        "Consider the following data. The train data has been divided into 4-folds\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/660/1*yesnizWjGSNGsUmlkhX18w.png\">\n",
        "\n",
        "We will be building an ensemble of 3 models. Each model will be trained on any 3 folds of the training data, and will make prediction on the 4th fold.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/624/1*yYFpm4Duauymbqmcs7pqTA.png\">\n",
        "\n",
        "This process will be repeated for all possible combinations of 3 folds, which will give a prediction for the entire training data. This is shown in the below image.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/624/1*zpYK59ERadLpks69gxANAw.png\">\n",
        "\n",
        "Similarly, we will do the same thing with 2 more models, and finally we will ahve 3 different sets of predictions on the entire training data, given by the 3 models we choose initially.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/624/1*Cuwvlt9nEh70o9RzFSFrTQ.png\">\n",
        "\n",
        "Finally, a meta-model will be trained with these predictions as features and the original target variable.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/624/1*BhSO1IVsXtbfMN6uIqKydA.png\">\n",
        "\n",
        "With stacking, the predictions of the meta-model on the test set will be better than the predictions of any of the 3 models alone on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKJpsXrGitDk"
      },
      "source": [
        "def Stacking(model,train,y,test,n_fold):\n",
        "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
        "    test_pred=np.empty((test.shape[0],1),float)\n",
        "    train_pred=np.empty((0,1),float)\n",
        "    \n",
        "    for train_indices,val_indices in folds.split(train,y.values):\n",
        "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
        "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
        "\n",
        "        model.fit(X=x_train,y=y_train)\n",
        "        train_pred=np.append(train_pred,model.predict(x_val))\n",
        "        \n",
        "    model.fit(train, y)\n",
        "    test_pred=model.predict(test)\n",
        "    return test_pred.reshape(-1,1),train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVpbBzBamdn1"
      },
      "source": [
        "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=x_train,test=x_test,y=y_train)\n",
        "\n",
        "train_pred1=pd.DataFrame(train_pred1)\n",
        "test_pred1=pd.DataFrame(test_pred1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdj6_Omhmhud"
      },
      "source": [
        "model2 = LogisticRegression()\n",
        "\n",
        "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)\n",
        "\n",
        "train_pred2=pd.DataFrame(train_pred2)\n",
        "test_pred2=pd.DataFrame(test_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZDAsLTQmm3p"
      },
      "source": [
        "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
        "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
        "\n",
        "model = LogisticRegression(random_state=1)\n",
        "model.fit(df,y_train)\n",
        "model.score(df_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizueAmjnTQY"
      },
      "source": [
        "stack = StackingClassifier(estimators=[('dt',model1),('lr',model2)], final_estimator=model)\n",
        "stack.fit(x_train,y_train)\n",
        "stack.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMkQRE-Xl8F7"
      },
      "source": [
        "##Another Way to Stack your models\n",
        "There is another library, called mlxtend that offers the Stacking Classifier.\n",
        "\n",
        "Here are the links to these:\n",
        "1.    [StackingClassifier](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/)\n",
        "2.    [StackingClassifierCV](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nr1n67be-Uw"
      },
      "source": [
        "# Blending "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSn4L3Q481b4"
      },
      "source": [
        "Blending is very similar to stacking, the only difference is that here we do not consider folds of training data, we rather split the training data into train and validation sets. This set is called the holdout set.\n",
        "<img src=\"https://miro.medium.com/max/624/1*5RXUF92qwpx-1BkcTejIoQ.png\">\n",
        "\n",
        "Rest of the process is same as that in stacking, we train 3 models on the train data, and each of them makes a prediction on the holdout set. These predictions are then used to train the meta-model.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/624/1*pvGUnMAycqvsYAwVe2LpHw.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLYJ8c5e-Uw"
      },
      "source": [
        "train, test = train_test_split(train, test_size=0.2, random_state=0)\n",
        "\n",
        "x_train=train.drop(['Loan_Status', 'Loan_ID'], axis=1)\n",
        "y_train=train['Loan_Status']\n",
        "\n",
        "x_val=test.drop(['Loan_Status', 'Loan_ID'], axis=1)\n",
        "y_val=test['Loan_Status']\n",
        "\n",
        "x_val = x_val.reset_index(drop = True)\n",
        "x_test = x_test.reset_index(drop = True)\n",
        "\n",
        "model1 = tree.DecisionTreeClassifier()\n",
        "model1.fit(x_train, y_train)\n",
        "\n",
        "val_pred1=model1.predict(x_val)\n",
        "test_pred1=model1.predict(x_test)\n",
        "\n",
        "val_pred1=pd.DataFrame(val_pred1)\n",
        "test_pred1=pd.DataFrame(test_pred1)\n",
        "\n",
        "model2 = LogisticRegression()\n",
        "model2.fit(x_train,y_train)\n",
        "\n",
        "val_pred2=model2.predict(x_val)\n",
        "test_pred2=model2.predict(x_test)\n",
        "\n",
        "val_pred2=pd.DataFrame(val_pred2)\n",
        "test_pred2=pd.DataFrame(test_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpksNnnle-Uw"
      },
      "source": [
        "df_val = pd.concat([x_val, val_pred1,val_pred2],axis=1)\n",
        "df_test = pd.concat([x_test, test_pred1,test_pred2],axis=1)\n",
        "\n",
        "model = LogisticRegression(random_state=1)\n",
        "model.fit(df_val,y_val)\n",
        "model.score(df_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9nPdcXh3aZi"
      },
      "source": [
        "# Stacking vs Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F54WoxM03dJO"
      },
      "source": [
        "The benefit of blending over stacking is that there is absolute no chance of any information leak here. Whereas in stacking, since we are training the base models on the entire train data, this method is not very robust against information leak.\n",
        "\n",
        "Although both give near similar results, the choice of which approach to take is more of a developer's personal choice. There is no clear demarcation which to use when, and which is better than the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMDiTopi10N"
      },
      "source": [
        "#Bagging and Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXkz36AL654t"
      },
      "source": [
        "Prof Raghavan covered these topics extensivel, we will not be going over them again.\n",
        "\n",
        "These are a few algorithms based on Bagging and Boosting:\n",
        "\n",
        "\n",
        "1.   Random Forest\n",
        "2.   XGBoost\n",
        "3.   AdaBoost\n",
        "4.   CatBoost\n",
        "5.   GBM\n",
        "6.   LightGBM\n",
        "\n",
        "If you have any queries, we are happy to take them up.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pE1uLTvjY6x"
      },
      "source": [
        "# Resources\n",
        "\n",
        "\n",
        "\n",
        "1.   [MLWave Article for Ensembling](https://mlwave.com/kaggle-ensembling-guide)\n",
        "2.   [Medium Article for Stacking and Blending](https://medium.com/@stevenyu530_73989/stacking-and-blending-intuitive-explanation-of-advanced-ensemble-methods-46b295da413c)\n",
        "3.   [TDS Article for Ensembling](https://towardsdatascience.com/ensemble-methods-in-machine-learning-what-are-they-and-why-use-them-68ec3f9fef5f)\n",
        "4.   [Analytics Vidhya Article for Ensembling](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/)\n",
        "5.   [Scikit-Learn Documentation for Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier)\n",
        "6.   [Various Averaging Techniques](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/165653)\n"
      ]
    }
  ]
}